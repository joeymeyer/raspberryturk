{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Determine if a Chessboard Square is Occupied or Empty\n",
    "\n",
    "## Introduction\n",
    "\n",
    "```\n",
    " <center><img src=\"/notebooks/assets/img/knightf7.jpg\" width=\"120px\"/></center>\n",
    " <center><i>Is there a piece in the square? If there is, what color is it?</i></center>\n",
    "```\n",
    "\n",
    "The answer may be obvious to us, but how can we write a program that can answer this question as accurately as we can? In this notebook we will approach this problem in two ways:\n",
    "\n",
    "1. **Detecting the colors of the pieces in the images manually**\n",
    "2. **A data driven approach, training a support vector machine for classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# @formatter:on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import project\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This dataset, `chess_piece_presence.npz`, was created using [`create_dataset.py`](https://github.com/joeymeyer/raspberryturk/blob/master/raspberryturk/core/data/create_dataset.py). It includes 79,872 rgb images of chessboard squares, either empty, or containing a orange or green piece of any kind. Each image is labeled as `0`: empty, `1`: green, `2`: orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from raspberryturk.core.data.dataset import Dataset\n",
    "d = Dataset.load_file(\"../data/processed/example_dataset.npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "17276400/(60*60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def convert_imgs(X):\n",
    "    norm_imgs = X.reshape((-1,60,60,4))\n",
    "    bgr_imgs = ((norm_imgs + 1.0) * 127.5).astype(np.uint8)\n",
    "    return np.array([cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB) for bgr_img in bgr_imgs])\n",
    "\n",
    "imgs = convert_imgs(d.X_train)\n",
    "validation_imgs = convert_imgs(d.X_val)\n",
    "label_names = [\"Empty\", \"Green\", \"Orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image(img_index, validation=False, title=None):\n",
    "    img = (validation_imgs if validation else imgs)[img_index]\n",
    "    if title is None:\n",
    "        label = (d.y_val if validation else d.y_train)[img_index]\n",
    "        title = label_names[label]\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_image(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Problem Using Color Masks\n",
    "\n",
    "By isolating the green and orange colors and detecting whether that color exists in the image, we should be able to determine if there is a piece on a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_kern = np.arange(0, 4, 1, float)\n",
    "y_kern = x_kern[:,np.newaxis]\n",
    "x_kern0 = y_kern0 = 4 // 2\n",
    "OPENING_KERNEL = np.uint8(np.exp(-4*np.log(2) * ((x_kern-x_kern0)**2 + (y_kern-y_kern0)**2) / 2**2) * 255)\n",
    "\n",
    "def mask(img, lower, upper):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, OPENING_KERNEL)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, OPENING_KERNEL)\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HSV Color Ranges\n",
    "GREEN_LOWER = (40,100,45)\n",
    "GREEN_UPPER = (120,255,255)\n",
    "ORANGE_LOWER = (0,100,64)\n",
    "ORANGE_UPPER = (20,255,255)\n",
    "\n",
    "def green_mask(img):\n",
    "    return mask(img, GREEN_LOWER, GREEN_UPPER)\n",
    "\n",
    "def orange_mask(img):\n",
    "    return mask(img, ORANGE_LOWER, ORANGE_UPPER)\n",
    "\n",
    "def combined_mask(img):\n",
    "    return green_mask(img) + orange_mask(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "start_index = 1000\n",
    "for i in range(start_index, start_index + 200):\n",
    "    img = imgs[i]\n",
    "    mask_img = cv2.bitwise_or(green_mask(img), orange_mask(img))\n",
    "    x = (i % 10) * 40\n",
    "    y = ((i % 200) / 10) * 20\n",
    "    c[y:y+20,x:x+20,:] = cv2.resize(img, (20,20))\n",
    "    c[y:y+20,x+20:x+40,0] = cv2.resize(mask_img, (20,20))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "If the there a certain number of pixels in the image that are within the color range, there is assumed to be a piece in that square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    threshold = 5.0\n",
    "    if np.sum(green_mask(img)) > threshold:\n",
    "        return 1\n",
    "    elif np.sum(orange_mask(img)) > threshold:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "The validation data is used to test the accuracy of the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = [predict(img) for img in validation_imgs]\n",
    "a = np.sum(pred == d.y_val) / float(d.y_val.shape[0])\n",
    "print \"Accuracy: {}\".format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from helpers import plot_confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(d.y_val, pred)\n",
    "plot_confusion_matrix(conf, classes=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Prediction\n",
    "\n",
    "Some pieces that are very close to the edge of their square occasionally appear in the sides of square next to it. The model should be updated to only base prediction on pixels within the color range that located towards the center of the image since that's were the piece will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image_index = 405\n",
    "actual_label = label_names[d.y_val[image_index]]\n",
    "predicted_label = label_names[predict(validation_imgs[image_index])]\n",
    "title = \"Actual: {} Predicted: {}\".format(actual_label, predicted_label)\n",
    "plot_image(image_index, validation=True, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = imgs.shape[1]\n",
    "x = np.arange(0, size, 1, float)\n",
    "y = x[:,np.newaxis]\n",
    "x0 = y0 = size // 2\n",
    "MASK_WEIGHTS = np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / (size*0.15)**2)\n",
    "\n",
    "def weighted_orange_mask(img):\n",
    "    return orange_mask(img) * MASK_WEIGHTS\n",
    "\n",
    "def weighted_green_mask(img):\n",
    "    return green_mask(img) * MASK_WEIGHTS\n",
    "\n",
    "def weighted_predict(img):\n",
    "    threshold = 5.0\n",
    "    if np.sum(weighted_green_mask(img)) > threshold:\n",
    "        return 1\n",
    "    elif np.sum(weighted_orange_mask(img)) > threshold:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_pred = [weighted_predict(img) for img in validation_imgs]\n",
    "a = np.sum(weighted_pred == d.y_val) / float(d.y_val.shape[0])\n",
    "print \"Accuracy: {}\".format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf = confusion_matrix(d.y_val, weighted_pred)\n",
    "plot_confusion_matrix(conf, classes=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Problem Using Machine Learning\n",
    "\n",
    "The next approach is to reduce the number of dimensions of each image by using PCA, and then building a support vector machine for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=16, whiten=True)\n",
    "pca.fit(d.X_train)\n",
    "X_train_pca = pca.transform(d.X_train)\n",
    "X_val_pca = pca.transform(d.X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "X_plot = X_train_pca[:300]\n",
    "y_plot = d.y_train[:300]\n",
    "\n",
    "sc = plt.scatter(X_plot[:,4], X_plot[:,8], c=y_plot, cmap=cm.cool, linewidths=0.4)\n",
    "occupied_patch = Patch(color='#ff30ff', label='Occupied')\n",
    "empty_patch = Patch(color='#30ffff', label='Empty')\n",
    "white_patch = Patch(color='#9898FF', label='White')\n",
    "black_patch = Patch(color='#ff30ff', label='Black')\n",
    "plt.legend(handles=[empty_patch, white_patch, black_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_pca, d.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(X_val_pca)\n",
    "a = np.sum(svc_pred == d.y_val) / float(d.y_val.shape[0])\n",
    "print \"Accuracy: {}\".format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = confusion_matrix(d.y_val, svc_pred)\n",
    "plot_confusion_matrix(conf, classes=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "\n",
    "Save the PCA and SVC for use in the vision portion of the Raspberry Turk. The support vector machine had slightly higher accuracy on the validation set, and is easier to adapt/scale with the addition of new data (different lighting conditions, different colored pieces, different camera, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(project.path('data', 'processed', 'square_color_detector3.pca'), 'w') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "with open(project.path('data', 'processed', 'square_color_detector3.svc'), 'w') as f:\n",
    "    pickle.dump(svc, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:turk]",
   "language": "python",
   "name": "conda-env-turk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
